{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio as tad\n",
    "import torchaudio.transforms as t\n",
    "import soxr\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  step last -> resampling\n",
    "def resample_audio(waveform: torch.Tensor,  orig_sample_rate: int, new_sample_rate: int = 22050):\n",
    "    resampled_numpy = soxr.resample(\n",
    "        x=waveform.numpy(),\n",
    "        in_rate=orig_sample_rate,\n",
    "        out_rate=new_sample_rate,\n",
    "        quality=\"VHQ\"\n",
    "    )\n",
    "    return torch.tensor(resampled_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1 -> loading audio\n",
    "def load_audio(audio_path):\n",
    "    waveform, sample_rate = tad.load(\n",
    "        uri=audio_path,\n",
    "        normalize=True,\n",
    "        channels_first=True,\n",
    "        backend=\"soundfile\",\n",
    "        buffer_size=512 # during development we will use -> 512, for testing in real device -> 256 – 512, final deployment -> 256–1024\n",
    "    )\n",
    "    return waveform, sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0000,  0.0000,  0.0000,  ..., -0.0045, -0.0060, -0.0078]]), 16000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform, sample_rate = load_audio(audio_path=r\"C:\\Users\\Admin\\Documents\\Mirage-Omega1\\ml_models\\ete_synthesis\\processed_audios\\mirage_1.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_trimming_aud(sample_rate, waveform):\n",
    "    vad = t.Vad(sample_rate=sample_rate)\n",
    "    vad_waveform = vad(waveform)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
